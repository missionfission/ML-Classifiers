{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bayes Classifier (with different class conditional densities and estimation techniques)\n",
    "2. Naive Bayes Classifier\n",
    "3. K-means Clustering\n",
    "4. K-Nearest Neighbor Classifier\n",
    "5. Principal component analysis (where ever applicable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Bayes Methods :\n",
    " 1. MLE\n",
    " 2. Bayesian Parameter Estimation\n",
    " 3. Expectation Maximization\n",
    " \n",
    "## Densities to implement :\n",
    "1. GMM\n",
    "2. Gaussian\n",
    "3. Bernoulli \n",
    "4. Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bayes:\n",
    "        def gaussian(self,train,y,n_c):\n",
    "        def binomial(self,train,y,n_c):\n",
    "        def multinomial(self,train,y,n_c):\n",
    "        def mle():\n",
    "        def gmm(self,train,y,n_c):\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naivebayes:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self,n_components,*args):\n",
    "        self.n=n_components\n",
    "    def fit_transform(self,train):\n",
    "        U, S, V = self.fit(X)\n",
    "        U = U[:, :self.n]\n",
    "        U *= S[:self.n]\n",
    "        return U\n",
    "    def fit(self,train):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X -= self.mean\n",
    "        U,S,V=np.linalg.svd(X,full_matrices=False)\n",
    "        self.components = V\n",
    "        return U,S,V\n",
    "    def transform(self,test):\n",
    "        output = np.dot(test, self.components.T)\n",
    "        return output\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get EigenVectors\n",
    "covMatrix = numpy.cov(imageList, rowvar=True)\n",
    "eigenVal, eigenVec = numpy.linalg.eig(covMatrix)\n",
    "# Make sure Eigenvectors are unit vectors\n",
    "numpy.testing.assert_array_almost_equal(1.0, numpy.linalg.norm(eigenVec[0]))\n",
    "# Reduce dimension thru eigen vector and save the resulting image\n",
    "largestEigenVec = eigenVec[0]\n",
    "result = largestEigenVec.T.dot(imageList)\n",
    "numpy.uint8(result.reshape(50,66)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self,k,*args)\n",
    "    self.k=k\n",
    "    def predict_one(self,train, y,test):\n",
    "        distances = []\n",
    "        for i in range(len(train)):\n",
    "            distance = ((train[i, :] - test)**2).sum()\n",
    "            distances.append([distance, i])\n",
    "        distances = sorted(distances)\n",
    "        targets = []\n",
    "        for i in range(self.k):\n",
    "            index_of_training_data = distances[i][1]\n",
    "            targets.append(y[index_of_training_data])\n",
    "        return Counter(targets).most_common(1)[0][0]\n",
    "\n",
    "    def result(self,train, y, test):\n",
    "        predictions = []\n",
    "        for x_test in test:\n",
    "            predictions.append(predict_one(train, y, x_test))\n",
    "        return predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian(a, b):\n",
    "    return np.linalg.norm(a-b)\n",
    "class k_means:\n",
    "    def __init__(self,k)\n",
    "        self.k=k\n",
    "    def fit(self,dataset,epsilon=0,*args):\n",
    "        history_centroids = []\n",
    "        dist_method = 'euclidian'\n",
    "        num_instances, num_features = train.shape\n",
    "        #define k centroids (how many clusters do we want to find?) chosen randomly \n",
    "        initial = train[np.random.randint(0, num_instances - 1, size=self.k)]\n",
    "        #set these to our list of past centroid (to show progress over time)\n",
    "        history_centroids.append(initial)\n",
    "        #to keep track of centroid at every iteration\n",
    "        prototypes_old = np.zeros(initial.shape)\n",
    "        #to store clusters\n",
    "        belongs_to = np.zeros((num_instances, 1))\n",
    "        norm = dist_method(initial, prototypes_old)\n",
    "        iteration = 0\n",
    "        while norm > epsilon:\n",
    "            iteration += 1\n",
    "            norm = dist_method(prototypes, prototypes_old)\n",
    "            #for each instance in the dataset\n",
    "            for index_instance, instance in enumrate(train):\n",
    "                #define a distance vector of size k\n",
    "                dist_vec = np.zeros((k,1))\n",
    "                #for each centroid\n",
    "                for index_prototype, prototype in enumerate(initial):\n",
    "                    #compute the distance between x and centroid\n",
    "                    dist_vec[index_prototype] = dist_method(prototype, instance)\n",
    "                #find the smallest distance, assign that distance to a cluster\n",
    "                belongs_to[index_instance, 0] = np.argmin(dist_vec)\n",
    "\n",
    "            tmp_prototypes = np.zeros((k, num_features))\n",
    "\n",
    "            #for each cluster (k of them)\n",
    "            for index in range(len(prototypes)):\n",
    "                #get all the points assigned to a cluster\n",
    "                instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "                #find the mean of those points, this is our new centroid\n",
    "                prototype = np.mean(dataset[instances_close], axis=0)\n",
    "                #add our new centroid to our new temporary list\n",
    "                tmp_prototypes[index, :] = prototype\n",
    "\n",
    "            #set the new list to the current list\n",
    "            prototypes = tmp_prototypes\n",
    "\n",
    "            #add our calculated centroids to our history for plotting\n",
    "            history_centroids.append(tmp_prototypes)\n",
    "\n",
    "        return prototypes, history_centroids, belongs_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(dataset, history_centroids, belongs_to):\n",
    "    #we'll have 2 colors for each centroid cluster\n",
    "    colors = ['r', 'g']\n",
    "\n",
    "    #split our graph by its axis and actual plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    #for each point in our dataset\n",
    "    for index in range(dataset.shape[0]):\n",
    "        #get all the points assigned to a cluster\n",
    "        instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "        #assign each datapoint in that cluster a color and plot it\n",
    "        for instance_index in instances_close:\n",
    "            ax.plot(dataset[instance_index][0], dataset[instance_index][1], (colors[index] + 'o'))\n",
    "\n",
    "    #lets also log the history of centroids calculated via training\n",
    "    history_points = []\n",
    "    #for each centroid ever calculated\n",
    "    for index, centroids in enumerate(history_centroids):\n",
    "        #print them all out\n",
    "        for inner, item in enumerate(centroids):\n",
    "            if index == 0:\n",
    "                history_points.append(ax.plot(item[0], item[1], 'bo')[0])\n",
    "            else:\n",
    "                history_points[inner].set_data(item[0], item[1])\n",
    "                print(\"centroids {} {}\".format(index, item))\n",
    "\n",
    "                plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
